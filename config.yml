dataset: kotlin # you can configure datasets with configs/datasets.yml

test_size: 0.1

tmpdir: null # if null default tmp directory will be used
log_file: null # set null for stdout
models_directory: text_models/saved/bert_base/kotlin_triplet
docs_directory: data/docs
docs_formats: ['html', 'pdf', 'md', 'rst'] # supported format extensions
model_types: ['TASK', 'PT_TASK', 'DOC_TASK', 'PT_DOC_TASK', 'BUGS_TASK', 'PT_BUGS_TASK', 'DOC_BUGS_TASK', 'PT_DOC_BUGS_TASK'] # supported training/evaluation types

text_model: siamese # see available text models in the corresponding section


evaluation:
  approach: simple # see available approaches in the corresponding section
  topns: [1, 5, 10, 15, 20, 25]
  save_results: true
  save_graph: true
  results_path: ./results/test

  is_tasks_test: true # available only if siamese text model will be used


approaches:
  intersection:
    min_count: 1

  tf_idf:
    weight: 0.7 # weight of tf-idf vectors similarity score in final score


models:
  random:
    vector_size: 300
    min_count: 1
    rand_by_w2v: false
    seed: 42
    save_to_path: text_models/saved

  word2vec:
    epochs: 100
    vector_size: 300
    min_count: 1
    tmp_file: null
    pretrained_model: word2vec-google-news-300 # must match vector_size
    seed: 42
    save_to_path: text_models/saved

  fasttext:
    epochs: 100
    vector_size: 300
    min_count: 1
    pretrained_model: text_models/pretrained/cc.en.300.bin # must match vector_size
    seed: 42
    save_to_path: text_models/saved
    
  siamese:
    vector_size: 300
    epochs: 8
    batch_size: 8
    n_examples: all
    save_best_model: false # When set to True, save_steps must be a round multiple of eval_steps.
    warmup_rate: 0.1 # percent of training data
    max_len: 512
    task_loss: triplet # 'triplet' or 'cossim'
    finetuning_strategies: ['mlm', 'tsdae'] # see available strategies in 'bert_tasks' section
    pretrained_model: bert-base-uncased
    evaluation_steps: 55
    val_size: 0.1
    tmp_file: null
    device: cuda # 'cpu' or 'cuda'
    start_train_from_task: false
    start_train_from_bugs: false
    seed: 42
    save_to_path: text_models/saved/test

    evaluator_config:
      batch_size: 8
      precision_recall_at_k: [1, 5, 10, 15, 20]
      accuracy_at_k: [1, 5, 10, 15, 20] # success rate like metric
      map_at_k: [5, 10] # validation metric


bert_tasks:
  mlm:
    epochs: 8
    batch_size: 8
    eval_steps: 250
    n_examples: all
    mask_probability: 0.15
    save_steps: 250
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.

  nsp:
    epochs: 2
    batch_size: 8
    eval_steps: 250
    n_examples: all
    forget_const: 10
    save_steps: 250
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.

  sase:
    epochs: 8
    batch_size: 8
    eval_steps: 250
    n_examples: all
    save_steps: 250
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.

  sts:
    epochs: 2
    batch_size: 8
    eval_steps: 250
    n_examples: all
    forget_const: 10
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.

  tsdae:
    epochs: 8
    batch_size: 8
    eval_steps: 250
    n_examples: all
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.
