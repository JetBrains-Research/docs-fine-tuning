dataset: idea # you can configure datasets with configs/datasets.yml

test_size: 0.1

tmpdir: null # if null default tmp directory will be used
log_file: data/logs/log_test.txt # data/logs/log_idea.txt # set null for stdout
docs_directory: data/docs
docs_formats: ['html', 'pdf', 'md', 'rst'] # supported format extensions
model_types: ['PT_DOC_TASK'] # supported training/evaluation types

text_model: siamese # see available text models in the corresponding section


evaluation:
  approach: simple # see available approaches in the corresponding section
  topns: [1, 5, 10, 15, 20, 25]
  save_results: true
  save_graph: true
  models_path: text_models/saved/bert_base/idea
  results_path: ./results/bert_base/idea

  is_tasks_test: true # available only if siamese text model will be used


approaches:
  intersection:
    min_count: 1

  tf_idf:
    weight: 0.7 # weight of tf-idf vectors similarity score in final score


models:
  random:
    vector_size: 300
    min_count: 1
    rand_by_w2v: false
    seed: 42
    save_to_path: text_models/saved

  word2vec:
    epochs: 100
    vector_size: 300
    min_count: 1
    tmp_file: null
    pretrained_model: word2vec-google-news-300 # must match vector_size
    seed: 42
    save_to_path: text_models/saved

  fasttext:
    epochs: 100
    vector_size: 300
    min_count: 1
    pretrained_model: text_models/pretrained/cc.en.300.bin # must match vector_size
    seed: 42
    save_to_path: text_models/saved
    
  siamese:
    vector_size: 300
    epochs: 12
    batch_size: 8
    n_examples: all
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.
    warmup_rate: 0.1 # percent of training data
    max_len: 512
    task_loss: triplet # 'triplet' or 'cossim'
    finetuning_strategies: ['mlm', 'tsdae'] # see available strategies in 'bert_tasks' section
    pretrained_model: bert-base-uncased # giganticode/bert-base-StackOverflow-comments_1M
    evaluation_steps: null
    save_steps: null
    val_size: 0.1
    tmp_file: null
    device: cuda # 'cpu' or 'cuda'
    start_train_from_task: false
    start_train_from_bugs: false
    seed: 42
    save_to_path: text_models/saved/test
    report_wandb: true

    evaluator_config:
      batch_size: 8
      precision_recall_at_k: [1, 5, 10, 15, 20]
      accuracy_at_k: [1, 5, 10, 15, 20] # success rate like metric
      map_at_k: [5, 10] # validation metric


bert_tasks:
  mlm:
    epochs: 12
    batch_size: 8
    eval_steps: null # if null then epoch mode will be used
    save_steps: null # if null then epoch mode will be used
    n_examples: all
    mask_probability: 0.15
    val: 0.1
    metric_for_best_model: task_map # 'task_map' or 'loss' or 'loss_task'
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.
    do_eval_on_artefacts: true

  nsp:
    epochs: 2
    batch_size: 8
    eval_steps: null # if null then epoch mode will be used
    save_steps: null # if null then epoch mode will be used
    n_examples: all
    forget_const: 10
    val: 0.1
    metric_for_best_model: task_map # 'task_map' or 'loss' or 'loss_task'
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.
    do_eval_on_artefacts: true

  sase:
    epochs: 8
    batch_size: 8
    eval_steps: null # if null then epoch mode will be used
    save_steps: null # if null then epoch mode will be used
    n_examples: all
    val: 0.1
    metric_for_best_model: task_map # 'task_map' or 'loss' or 'loss_task'
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.
    do_eval_on_artefacts: true

  sts:
    epochs: 2
    batch_size: 8
    eval_steps: null # if null then epoch mode will be used
    save_steps: null # if null then epoch mode will be used
    n_examples: all
    forget_const: 10
    val: 0.1
    metric_for_best_model: task_map # 'task_map' or 'loss' or 'loss_task'
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.
    do_eval_on_artefacts: true

  tsdae:
    epochs: 12
    batch_size: 8
    eval_steps: null # if null then epoch mode will be used
    save_steps: null # if null then epoch mode will be used
    n_examples: all
    val: 0.1
    metric_for_best_model: task_map # 'task_map' or 'loss' or 'loss_task'
    save_best_model: true # When set to True, save_steps must be a round multiple of eval_steps.
    do_eval_on_artefacts: true
